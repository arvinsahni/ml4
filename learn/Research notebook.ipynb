{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%file utils.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "error_messages = {\n",
    "    \"No clear target in training data\": \n",
    "        (\"The training data must have \" \n",
    "         \"exactly one more column than \" \n",
    "         \"the test data.\"),\n",
    "    \"Training data has too many columns\":\n",
    "        (\"The training data has more \"\n",
    "         \"than one column different than \"\n",
    "         \"the testing data: %s\"),\n",
    "    \"Column names inconsistent\":\n",
    "        (\"The training columns and the \"\n",
    "         \"test columns must have \"\n",
    "         \"identical names excepts for \"\n",
    "         \"the target variables. \"\n",
    "         \"Different columns: %s\")\n",
    "    }\n",
    "\n",
    "def X_y_split(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Determines which variables are the target\n",
    "    and which are the features. Returns just\n",
    "    The X and y data in the training dataset\n",
    "    as a tuple.\n",
    "    \n",
    "    Example usage:\n",
    "    X, y = learn.X_y_split(X_train, X_test)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: pandas dataframe\n",
    "        The data that has the target in it.\n",
    "    \n",
    "    X_test: pandas dataframe\n",
    "        The data that does not have the target in it.\n",
    "    \"\"\"\n",
    "    X_train = X_train.copy()\n",
    "    n_train_cols = X_train.shape[1]\n",
    "    n_test_cols = X_test.shape[1]\n",
    "    \n",
    "    if n_train_cols != n_test_cols + 1:\n",
    "        msg = error_messages[\"No clear target in training data\"]\n",
    "        raise ValueError(msg)\n",
    "        \n",
    "    test_columns = set(X_test.columns)\n",
    "    train_columns = set(X_train.columns)\n",
    "    target_columns = train_columns - test_columns\n",
    "    if len(target_columns) > 1:\n",
    "        key = \"Training data has too many columns\"\n",
    "        msg_ = error_messages[key]\n",
    "        msg = msg_ % str(target_columns)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    extra_columns_in_test = test_columns - train_columns\n",
    "    if extra_columns_in_test:\n",
    "        key = \"Column names inconsistent\"\n",
    "        msg_ = error_messages[key]\n",
    "        msg = msg_ % str(extra_columns_in_test)\n",
    "        raise ValueError(msg)     \n",
    "\n",
    "    y_name = target_columns.pop()\n",
    "    y = X_train.pop(y_name)\n",
    "    return X_train, y\n",
    "\n",
    "\n",
    "def make_data(source, \n",
    "              missing_data=None, \n",
    "              categorical=None, \n",
    "              outliers=None):\n",
    "    \"\"\"\n",
    "    Utility function to assist in loading different \n",
    "    sample datasets. Returns training data (that \n",
    "    contains the target) and testing data (that\n",
    "    does not contain the target).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source: string, optional (default=\"boston\")\n",
    "        The specific dataset to load. Options:\n",
    "        - Regression: \"boston\", \"diabetes\"\n",
    "        - Classification: \"cancer\", \"digits\", \"iris\"\n",
    "        \n",
    "    missing_data: bool or NoneType (default=None)\n",
    "        To be implemented\n",
    "        Determines if there is missing data\n",
    "        \n",
    "    categorical: bool or NoneType (default=None)\n",
    "        To be implemented\n",
    "        Determines if there is categorical data\n",
    "        \n",
    "    outliers: bool or NoneType (default=None)\n",
    "        To be implemented\n",
    "        Determines if there are outliers in the dataset\n",
    "    \"\"\"\n",
    "    if source == \"boston\":\n",
    "        data = datasets.load_boston()\n",
    "    elif source == \"diabetes\":\n",
    "        data = datasets.load_diabetes()\n",
    "        data[\"feature_names\"] = [\"f{}\".format(v) \n",
    "                                 for v in range(10)]\n",
    "    elif source == \"cancer\":\n",
    "        data = datasets.load_breast_cancer()\n",
    "    elif source == \"digits\":\n",
    "        data = datasets.load_digits()\n",
    "        data[\"feature_names\"] = [\"f{}\".format(v) \n",
    "                                 for v in range(64)]        \n",
    "    elif source == \"iris\":\n",
    "        data = datasets.load_iris()\n",
    "    X = pd.DataFrame(data=data.data, \n",
    "                     columns=data.feature_names)\n",
    "    y = pd.Series(data=data.target)\n",
    "    X_train, X_test, y_train, _ = train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   test_size=.5,\n",
    "                                                   random_state=42)\n",
    "    X_train[\"target\"] = y_train\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def is_classification_problem(y, max_classes=\"auto\"):\n",
    "    \"\"\"\n",
    "    Check if a target variable is a classification\n",
    "    problem or a regression problem. Returns True if\n",
    "    classification and False if regression. On failure,\n",
    "    raises a ValueError.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: array-like\n",
    "        This should be the target variable. Ideally, \n",
    "        you should convert it to be numeric before \n",
    "        using this function.\n",
    "        \n",
    "    max_classes: int or float, optional (default=\"auto\")\n",
    "        Determines the max number of unique target values\n",
    "        there can be for classification problems\n",
    "        \n",
    "        If \"auto\" - sets it equal to 10% of the dataset or\n",
    "            100, whichever is smaller\n",
    "        If float - interprets as percent of dataset size\n",
    "        If int - interprets as number of classes\n",
    "    \"\"\"\n",
    "    y = pd.Series(y)\n",
    "    n = len(y)\n",
    "    n_unique = len(y.unique())\n",
    "    if max_classes == \"auto\":\n",
    "        n_max_classes = int(n*.1)\n",
    "        max_classes = min(n_max_classes, 100)\n",
    "    if isinstance(max_classes, float):\n",
    "        n_max_classes = int(n*max_classes)\n",
    "        max_classes = min(n_max_classes, int(n/2))\n",
    "    # If y is numeric\n",
    "    if y.dtype.kind in 'bifc':\n",
    "        # If there are more than max_classes\n",
    "        # classify as a regression problem\n",
    "        if n_unique > max_classes:\n",
    "            return False\n",
    "        # If there are floating point numbers\n",
    "        # classify as a regression problem\n",
    "        decimals = (y - y.astype(int)).mean()\n",
    "        if decimals > .01:\n",
    "            return False\n",
    "    if n_unique <= max_classes:\n",
    "        return True\n",
    "    try:\n",
    "        y.astype(float)\n",
    "        return False\n",
    "    except ValueError:\n",
    "        msg = (\"Malformed target data. \"\n",
    "               \"Target is non-numeric \"\n",
    "               \"and there are more \"\n",
    "               \"unique values than allowed \"\n",
    "               \"by max_classes\")\n",
    "        raise ValueError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../tests/test_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../tests/test_utils.py\n",
    "import unittest\n",
    "from learn import utils\n",
    "\n",
    "class TestUtils(unittest.TestCase):\n",
    "    def test_making_data_simple(self):\n",
    "        for data in [\"boston\", \"iris\"]:\n",
    "            X_train, X_test = utils.make_data(source=data)\n",
    "            train_cols = X_train.columns\n",
    "            test_cols = X_test.columns\n",
    "            # Training data should have exactly one additional column\n",
    "            self.assertEqual(len(train_cols), len(test_cols)+1)\n",
    "            # Ensure only one column name is different\n",
    "            n_diff_cols = len(set(X_train.columns) - set(X_test.columns))\n",
    "            self.assertEqual(1, n_diff_cols)\n",
    "        \n",
    "    def test_is_classification_problem(self):\n",
    "        # Shorten function name\n",
    "        icp = utils.is_classification_problem\n",
    "        # Regression because floats\n",
    "        result = icp([1.1, 2.1])\n",
    "        self.assertEqual(result, 0)\n",
    "        # Regression because number of unique\n",
    "        result = icp([1,2,3,4])\n",
    "        self.assertEqual(result, 0)\n",
    "        # Classification because words\n",
    "        result = icp([\"cat\"]*20+[\"dog\"]*20)\n",
    "        self.assertEqual(result, 1)\n",
    "        # Classification because number of uniques\n",
    "        result = icp([0]*20+[1]*20)\n",
    "        self.assertEqual(result, 1)\n",
    "        # Real data tests - Regression\n",
    "        for dataset in [\"boston\", \"diabetes\"]:\n",
    "            data = utils.make_data(source=dataset)\n",
    "            X, y = utils.X_y_split(*data)\n",
    "            self.assertEqual(icp(y), 0)\n",
    "        # Real data tests - Classification\n",
    "        for dataset in [\"cancer\", \"digits\", \"iris\"]:\n",
    "            data = utils.make_data(source=dataset)\n",
    "            X, y = utils.X_y_split(*data)\n",
    "            self.assertEqual(icp(y), 1)\n",
    "            \n",
    "# class TestXYSplit(unittest.TestCase):\n",
    "#     pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting forall.py\n"
     ]
    }
   ],
   "source": [
    "%%file forall.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from learn import utils\n",
    "\n",
    "class Regression():\n",
    "    def __init__(self, time_to_compute=None):\n",
    "        self.time_to_compute = time_to_compute\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        model = RandomForestRegressor(n_estimators=100, \n",
    "                                      oob_score=True)\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        self.oob_predictions = model.oob_prediction_\n",
    "        self.score_type = \"R2\"\n",
    "        self.score = r2_score(y, self.oob_predictions)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "class Classification():\n",
    "    def __init__(self, time_to_compute=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.time_to_compute = time_to_compute\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Currently y must be numeric. Wrap \n",
    "        LabelVectorizer as TODO.\n",
    "        \"\"\"\n",
    "        y = pd.Series(y)\n",
    "        self.n_classes = len(y.unique())\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                       oob_score=True)\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        \n",
    "        # Evaluation metrics\n",
    "        if self.n_classes == 2:\n",
    "            self.oob_predictions = model.oob_decision_function_[:, 1]\n",
    "            self.score_type = \"AUC\"\n",
    "            self.score = roc_auc_score(y, self.oob_predictions)\n",
    "        else:\n",
    "            self.oob_predictions = model.oob_decision_function_\n",
    "            self.score_type = \"AUC\"\n",
    "            y_bin = label_binarize(y, sorted(pd.Series(y).unique()))\n",
    "            self.score = roc_auc_score(y_bin, \n",
    "                                       self.oob_predictions)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions\n",
    "\n",
    "    \n",
    "class All():\n",
    "    def __init__(self, time_to_compute=None):\n",
    "        self.time_to_compute = time_to_compute\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classification = utils.is_classification_problem(y)\n",
    "        if self.classification:\n",
    "            model = Classification()\n",
    "        else:\n",
    "            model = Regression()\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        self.score = model.score\n",
    "        self.score_type = model.score_type\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Allows importing of local modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from learn import forall as fa\n",
    "from learn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston: 0.814 (R2)\n",
      "diabetes: 0.435 (R2)\n",
      "cancer: 0.980 (AUC)\n",
      "digits: 0.998 (AUC)\n",
      "iris: 0.981 (AUC)\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"boston\", \"diabetes\", \"cancer\", \"digits\", \"iris\"]:\n",
    "    # In the flask app:\n",
    "    X_train, X_test = utils.make_data(source=dataset)\n",
    "    X, y = utils.X_y_split(X_train=X_train, X_test=X_test)\n",
    "    model = fa.All()\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"%s: %.3f (%s)\" % (dataset, model.score, model.score_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
